{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#2 Preprocesamiento\n"
      ],
      "metadata": {
        "id": "gAKCHtdvY1EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.0 Conectar con Drive y copiar archivos"
      ],
      "metadata": {
        "id": "2BWja3_4E5bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Monto Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl13ijM7E5AB",
        "outputId": "37f45725-7f3e-434a-dea4-172380bc494f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copiar el archivo de Drive a Colab\n",
        "\n",
        "!cp \"/content/drive/My Drive/Video_Games_processed.csv\" \"/content/Video_Games_processed.csv\""
      ],
      "metadata": {
        "id": "8ncCzk6CFC3E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1 Leer archivo y cargas en dataframe"
      ],
      "metadata": {
        "id": "rnlXwgf81Zlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar librerias necesarias\n",
        "\n",
        "! pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMVkUCEhwLN4",
        "outputId": "43cb9f59-3b33-4019-ec03-60536fa1331a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting num2words\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m133.1/143.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6.2 (from num2words)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9d00060a2423b84c62a0acf2cc5d9f1816eb951aa090bbf9c5d0153d2ea847e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, num2words\n",
            "Successfully installed docopt-0.6.2 num2words-0.5.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerias necesarias\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from num2words import num2words\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Inicializa el lematizador\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KA8WJ0b32xC",
        "outputId": "7f66594f-9cfd-4045-9a45-4a663316b5dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifico que el archivo se haya descargado correctamente\n",
        "\n",
        "!ls -l \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlhQXbEu0Mvk",
        "outputId": "d9ef071c-6b7c-4b81-ab10-d7260daefc73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 10444\n",
            "drwx------ 5 root root     4096 Mar 28 15:37 drive\n",
            "drwxr-xr-x 1 root root     4096 Mar 26 13:28 sample_data\n",
            "-rw------- 1 root root 10683869 Mar 28 15:37 Video_Games_processed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leo el archivo generador en el Ejercicio 1\n",
        "\n",
        "# Ruta completa al archivo CSV en google drive\n",
        "ruta_archivo_csv = f\"/content/Video_Games_processed.csv\"\n",
        "\n",
        "# Cargar el archivo CSV en un DataFrame\n",
        "df = pd.read_csv(ruta_archivo_csv)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame para verificar\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4UVcnuz0ohR",
        "outputId": "cee7cc04-2121-4e46-b80a-dedcc2d29233"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   overall                                         reviewText  sentiment\n",
            "0      4.0  I had to learn the hard way after ordering thi...          1\n",
            "1      4.0  I would recommend this learning game for anyon...          1\n",
            "2      5.0  Choose your career which sets your money for t...          1\n",
            "3      5.0  It took a few hours to get this up and running...          1\n",
            "4      5.0  I oredered this for a daughter who is now 33 a...          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Pipeline de procesamiento"
      ],
      "metadata": {
        "id": "VqBVB01_0NYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion pipeline de preprocesamiento\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Me aseguro de que no haya problemas de enconding\n",
        "    if not isinstance(text, str):\n",
        "      text = str(text, encoding='utf-8', errors='replace')\n",
        "\n",
        "    # Convertir el texto a minusculas para normalizar\n",
        "    text = text.lower()\n",
        "\n",
        "    # convertir digitos a palabras\n",
        "    if text.isdigit():\n",
        "      text = num2words(text, lang='en')\n",
        "\n",
        "    # Eliminar puntuaciones y simbolos\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Tokenizar\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Eliminar stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lematización\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "-hN2Mhh5ZRPX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Aplicar el preprocesamiento"
      ],
      "metadata": {
        "id": "sykKHavy0S2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar preprocesamiento\n",
        "\n",
        "df['reviewText'] = df['reviewText'].astype(str)  # Asegurar que el texto sea string\n",
        "\n",
        "df['tokens'] = df['reviewText'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "PPydGx5fZkLk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las primeras filas del DataFrame para verificar\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YigEEU32HUZ9",
        "outputId": "a073c4d2-98eb-47bf-b21e-1d564cbe5cb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   overall                                         reviewText  sentiment  \\\n",
            "0      4.0  I had to learn the hard way after ordering thi...          1   \n",
            "1      4.0  I would recommend this learning game for anyon...          1   \n",
            "2      5.0  Choose your career which sets your money for t...          1   \n",
            "3      5.0  It took a few hours to get this up and running...          1   \n",
            "4      5.0  I oredered this for a daughter who is now 33 a...          1   \n",
            "\n",
            "                                              tokens  \n",
            "0  [learn, hard, way, ordering, macbook, pro, doe...  \n",
            "1  [would, recommend, learning, game, anyone, lik...  \n",
            "2  [choose, career, set, money, trip, name, many,...  \n",
            "3  [took, hour, get, running, window, computer, w...  \n",
            "4  [oredered, daughter, wanted, play, oregon, tra...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.3 Guardar el archivo prepocesado para posterior uso"
      ],
      "metadata": {
        "id": "ZwKQPOzk4-M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardo el archivo preprocesado para su posterior uso\n",
        "\n",
        "ruta_destino_csv = f\"/content/Video_Games_Preprocessed.csv\"\n",
        "\n",
        "df.to_csv(ruta_destino_csv, index=False)"
      ],
      "metadata": {
        "id": "ERS2agaV4GTl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l \"/content/\""
      ],
      "metadata": {
        "id": "XEfGZY6719ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9db136-f6da-4d87-9b7b-56c20c56cbcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 30032\n",
            "drwx------ 5 root root     4096 Mar 28 15:37 drive\n",
            "drwxr-xr-x 1 root root     4096 Mar 26 13:28 sample_data\n",
            "-rw-r--r-- 1 root root 20054410 Mar 28 15:38 Video_Games_Preprocessed.csv\n",
            "-rw------- 1 root root 10683869 Mar 28 15:37 Video_Games_processed.csv\n"
          ]
        }
      ]
    }
  ]
}