{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Evaluacion de los modelos y conclusiones"
      ],
      "metadata": {
        "id": "H6VbsBvJDVqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerias\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "MVADWh9kIMdn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.0 Conectar al Drive"
      ],
      "metadata": {
        "id": "jE_Tx68_tei9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Monto Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rjSo_5otfPC",
        "outputId": "bfca3b17-7d61-4f75-c4d2-311ce43390d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.1 Copiar y cargar de los modelos\n"
      ],
      "metadata": {
        "id": "RV7YnWxYEvjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copiar el modelos de Drive a Colab\n",
        "!cp \"/content/drive/My Drive/model_lr.pkl\" \"/content/model_lr.pkl\"\n",
        "!cp \"/content/drive/My Drive/model_nb.pkl\" \"/content/model_nb.pkl\"\n",
        "!cp \"/content/drive/My Drive/model_rnn.keras\" \"/content/model_rnn.keras\"\n",
        "!cp \"/content/drive/My Drive/model_lstm.h5\" \"/content/model_lstm.h5\""
      ],
      "metadata": {
        "id": "kN9XJxCPtRJP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los modelos LR y NB\n",
        "\n",
        "from joblib import load\n",
        "\n",
        "model_lr = load('/content/model_lr.pkl')\n",
        "model_nb = load('/content/model_nb.pkl')\n",
        "model_rnn = load_model('/content/model_rnn.keras')\n",
        "model_lstm = load_model('/content/model_lstm.h5')"
      ],
      "metadata": {
        "id": "MchzcbHKE0xN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.2 Copiar y cargar los datos"
      ],
      "metadata": {
        "id": "lF_0Njt0ET11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copio los datos de Drive a Colab\n",
        "# (en ocasiones demora, hay que darle tiempo o ejecutarlo mas de una vez)\n",
        "\n",
        "!cp \"/content/drive/My Drive/X_train_scaled.npz\" \"/content/X_train_scaled.npz\"\n",
        "!cp \"/content/drive/My Drive/X_test_scaled.npz\" \"/content/X_test_scaled.npz\"\n",
        "!cp \"/content/drive/My Drive/y_test.npy\" \"/content/y_test.npy\"\n",
        "!cp \"/content/drive/My Drive/X_test_pad.npy\" \"/content/X_test_pad.npy\""
      ],
      "metadata": {
        "id": "drYlXzUP3Owj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My3zuI9A8J_U",
        "outputId": "71393477-dbc5-48e1-b9d5-3a653e61c788"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 44796\n",
            "drwx------ 5 root root     4096 Mar 28 15:43 drive\n",
            "-rw------- 1 root root   259919 Mar 28 15:43 model_lr.pkl\n",
            "-rw------- 1 root root   814680 Mar 28 15:43 model_lstm.h5\n",
            "-rw------- 1 root root  1036983 Mar 28 15:43 model_nb.pkl\n",
            "-rw------- 1 root root   511912 Mar 28 15:43 model_rnn.keras\n",
            "drwxr-xr-x 1 root root     4096 Mar 26 13:28 sample_data\n",
            "-rw------- 1 root root 37616128 Mar 28 15:43 X_test_pad.npy\n",
            "-rw------- 1 root root  1096956 Mar 28 15:43 X_test_scaled.npz\n",
            "-rw------- 1 root root  4483271 Mar 28 15:43 X_train_scaled.npz\n",
            "-rw------- 1 root root    32128 Mar 28 15:43 y_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargo las variables para la evaluacion de los modelos\n",
        "\n",
        "import numpy as np\n",
        "from scipy.sparse import save_npz, load_npz\n",
        "\n",
        "X_train_scaled = load_npz('/content/X_train_scaled.npz')\n",
        "X_test_scaled = load_npz('/content/X_test_scaled.npz')\n",
        "y_test = np.load('/content/y_test.npy', allow_pickle=True)\n",
        "X_test_pad = np.load('/content/X_test_pad.npy', allow_pickle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "77BMO18vIRE0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.3 Evaluacion de los modelos"
      ],
      "metadata": {
        "id": "WnkKbpC9-otX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Evaluación de los Modelos\n",
        "\n",
        "# Evaluar Regresión Logística\n",
        "y_pred_lr = model_lr.predict(X_test_scaled)\n",
        "\n",
        "print(\"Regresión Logística:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Evaluar Naive Bayes\n",
        "y_pred_nb = model_nb.predict(X_test_scaled)\n",
        "print(\"Naive Bayes:\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Evaluar RNN\n",
        "y_pred_rnn = (model_rnn.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"RNN:\")\n",
        "print(classification_report(y_test, y_pred_rnn))\n",
        "\n",
        "# Evaluar LSTM\n",
        "y_pred_lstm = (model_lstm.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "print(\"LSTM:\")\n",
        "print(classification_report(y_test, y_pred_lstm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdEUrSvJETVS",
        "outputId": "f05782a2-3710-4200-bbe3-506dc0e02e29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Logística:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      1981\n",
            "           1       0.85      0.86      0.85      2019\n",
            "\n",
            "    accuracy                           0.85      4000\n",
            "   macro avg       0.85      0.85      0.85      4000\n",
            "weighted avg       0.85      0.85      0.85      4000\n",
            "\n",
            "Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.77      1981\n",
            "           1       0.77      0.76      0.77      2019\n",
            "\n",
            "    accuracy                           0.77      4000\n",
            "   macro avg       0.77      0.77      0.77      4000\n",
            "weighted avg       0.77      0.77      0.77      4000\n",
            "\n",
            "125/125 [==============================] - 18s 136ms/step\n",
            "RNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.66      1981\n",
            "           1       0.00      0.00      0.00      2019\n",
            "\n",
            "    accuracy                           0.50      4000\n",
            "   macro avg       0.25      0.50      0.33      4000\n",
            "weighted avg       0.25      0.50      0.33      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 36s 285ms/step\n",
            "LSTM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.66      1981\n",
            "           1       0.00      0.00      0.00      2019\n",
            "\n",
            "    accuracy                           0.50      4000\n",
            "   macro avg       0.25      0.50      0.33      4000\n",
            "weighted avg       0.25      0.50      0.33      4000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar LR\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Regresión Logistica - Accuracy: {accuracy_lr}\\n\")\n",
        "\n",
        "# Evaluar NB\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(f\"Naive Bayes - Accuracy: {accuracy_nb}\")\n",
        "\n",
        "# Evaluar RNN\n",
        "loss_rnn, accuracy_rnn = model_rnn.evaluate(X_test_pad, y_test, verbose=0)\n",
        "print(f\"RNN - Loss: {loss_rnn}, Accuracy: {accuracy_rnn}\")\n",
        "\n",
        "# Evaluar LSTM\n",
        "loss_lstm, accuracy_lstm = model_lstm.evaluate(X_test_pad, y_test, verbose=0)\n",
        "print(f\"LSTM - Loss: {loss_lstm}, Accuracy: {accuracy_lstm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwptr0GVyXS1",
        "outputId": "a0629153-449a-4e64-ab58-35b65e186d7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Logistica - Accuracy: 0.85125\n",
            "\n",
            "Naive Bayes - Accuracy: 0.7665\n",
            "RNN - Loss: 0.6946031451225281, Accuracy: 0.49524998664855957\n",
            "LSTM - Loss: 0.6932557821273804, Accuracy: 0.49524998664855957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.4 Conclusiones"
      ],
      "metadata": {
        "id": "CqNzUqZFFAJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RENDIMINETO\n",
        "\n",
        "Regresion Logistica\n",
        "  Ha mostrado un rendimiento bueno en terminos de precision, recall y f1-score para las dos clases. La RL ha logrado capturar la relacion entre las entradas y salidad de forma efectiva para estos datos.\n",
        "Naive Bayes\n",
        "  Ligeramente inferior que la RL, pero con un rendimiento bueno. Sin embargo recall y f1-score son mas bajos que los de RL. Esto puede deberse a las caracteristicas del modelo.\n",
        "RNN y LSTM\n",
        "  Rendimiento muy pobre, la precision del 50% es casi como el azar. Esto puede deberse a varios factores como el entrenamiento insuficinete, las arquitectura de los modelos no es adecuada para la tarea o la necesidad de ajustar los hiperparametros\n",
        "\n",
        "### CONCLUSION GENERAL\n",
        "\n",
        "La RL ha sido el modelo mas efectivo para este conjunto de datos con un buen rendimienot de Naive Bayes. El pobre resultado de RNN y LSTM sugieren que necesita hacerse una revision mas profunda para estos modelos y dejan en evidencia la importancia de probar diferentes modelos para un problema de clasificacion, ya que no siempre los modelos mas complejos garantizan el mejor rendimiento.\n",
        "\n",
        "### NOTA IMPORTANTE\n",
        "\n",
        "Las limitaciones del entorno condicionaron la ejecucion de mejoras en los modelos, tantos las mencioandas como otras que hemos visto a lo largo del curso."
      ],
      "metadata": {
        "id": "5tEvZcPo_Bzm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Ewc6QvXFl6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}